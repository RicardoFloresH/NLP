{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fa3e07c",
   "metadata": {},
   "source": [
    "## Semantic Analysis with BERT fine-tune\n",
    "#### data source: Amazon Fine Food Reviews\n",
    "#### Ricardo Flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaad50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# BERT (transformers)\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# torch\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e600a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # calculate accuracy using sklearn's function\n",
    "    precision = precision_score(labels, preds)\n",
    "    recall = recall_score(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds)\n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'Accuracy': acc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799b8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data (sampling 1% of original data)\n",
    "df_review = pd.read_csv('./data/Reviews_1percent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ccb8982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127276</td>\n",
       "      <td>5</td>\n",
       "      <td>There is something to be said about this candy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395444</td>\n",
       "      <td>5</td>\n",
       "      <td>In many languages around the world, \"chai\" sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>225935</td>\n",
       "      <td>1</td>\n",
       "      <td>Review of Asian Taste Dried Mushroom, 5-Ounce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562268</td>\n",
       "      <td>5</td>\n",
       "      <td>Great flavor. I have always ordered Blue Diamo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>491584</td>\n",
       "      <td>3</td>\n",
       "      <td>The product came with a crushed box but was OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>407146</td>\n",
       "      <td>4</td>\n",
       "      <td>For the amount of money spent on this product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>323379</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this product. It's really a great way t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>455703</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow! This jerky is delicious! I have purchased...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5683</th>\n",
       "      <td>563011</td>\n",
       "      <td>5</td>\n",
       "      <td>The soft baked cookies are amazingly delicious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5684</th>\n",
       "      <td>404112</td>\n",
       "      <td>4</td>\n",
       "      <td>I found this product on a doctors website.  It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5685 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Score                                               Text\n",
       "0     127276      5  There is something to be said about this candy...\n",
       "1     395444      5  In many languages around the world, \"chai\" sim...\n",
       "2     225935      1  Review of Asian Taste Dried Mushroom, 5-Ounce ...\n",
       "3     562268      5  Great flavor. I have always ordered Blue Diamo...\n",
       "4     491584      3  The product came with a crushed box but was OK...\n",
       "...      ...    ...                                                ...\n",
       "5680  407146      4  For the amount of money spent on this product ...\n",
       "5681  323379      5  I love this product. It's really a great way t...\n",
       "5682  455703      5  Wow! This jerky is delicious! I have purchased...\n",
       "5683  563011      5  The soft baked cookies are amazingly delicious...\n",
       "5684  404112      4  I found this product on a doctors website.  It...\n",
       "\n",
       "[5685 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant columns \n",
    "df_review = df_review[['Id', 'Score', 'Text']]\n",
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f3209c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels \n",
    "label = []\n",
    "for i in df_review.Score:\n",
    "    if i > 3:\n",
    "        label.append(1) # positive \n",
    "    else:\n",
    "        label.append(0) # negative\n",
    "df_review[\"Label\"] = label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d5b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (3979,) (3979,)\n",
      "Test data: (1706,) (1706,)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "data = df_review['Text']\n",
    "y = df_review['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.3, stratify=y, random_state = 124)\n",
    "\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4b5762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (6192,) (6192,)\n",
      "Test data: (1706,) (1706,)\n"
     ]
    }
   ],
   "source": [
    "# Upsampling \n",
    "train = pd.DataFrame({'text':X_train, 'label':y_train})\n",
    "\n",
    "#Count 1s and 0s\n",
    "ones = len(train.loc[train['label'] == 1])\n",
    "zeros = len(train.loc[train['label'] == 0])\n",
    "if ones >= zeros:\n",
    "    majority = 1\n",
    "    minority = 0\n",
    "else:\n",
    "    majority = 0\n",
    "    minority = 1\n",
    "    \n",
    "# Upsample TrainingSet\n",
    "train_majority = train[train.label==majority]\n",
    "train_minority = train[train.label==minority]\n",
    "\n",
    "# Upsample minority class\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(train_majority),    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "train = pd.concat([train_majority, train_minority_upsampled])\n",
    "\n",
    "X_train = train['text']\n",
    "y_train = train['label']\n",
    "\n",
    "print(\"Train data:\",  X_train.shape, y_train.shape)\n",
    "print(\"Test data:\",  X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ec8f8a",
   "metadata": {},
   "source": [
    "## BERT with fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bd68598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model we gonna train, base uncased BERT\n",
    "# check text classification models here: https://huggingface.co/models?filter=text-classification\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# max sequence length for each document/sentence sample\n",
    "max_length = 256 # 256, 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b7cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "#tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)\n",
    "#tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "from transformers import DistilBertTokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db20a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataset, truncate when passed `max_length`, \n",
    "# and pad with 0's when less than `max_length`\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=max_length)\n",
    "valid_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27c1c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43dd0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = NewsGroupsDataset(train_encodings, y_train.tolist())\n",
    "valid_dataset = NewsGroupsDataset(valid_encodings, y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32ab2712",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "#model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2).to(\"cuda\")\n",
    "model =  DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "099df278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total number of training epochs\n",
    "    per_device_train_batch_size=4,  # batch size per device during training\n",
    "    per_device_eval_batch_size=4,   # batch size for evaluation\n",
    "    warmup_steps=500,             # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=500,         # log & save weights each logging_steps\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cabce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=valid_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a827e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 6192\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1548\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1548' max='1548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1548/1548 02:18, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.560600</td>\n",
       "      <td>0.441802</td>\n",
       "      <td>0.895415</td>\n",
       "      <td>0.941265</td>\n",
       "      <td>0.917768</td>\n",
       "      <td>0.868699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.436394</td>\n",
       "      <td>0.947697</td>\n",
       "      <td>0.914157</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.893904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.256800</td>\n",
       "      <td>0.460086</td>\n",
       "      <td>0.932442</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.939065</td>\n",
       "      <td>0.904455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1706\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1706\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./results\\checkpoint-1000\n",
      "Configuration saved in ./results\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1706\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./results\\checkpoint-1500\n",
      "Configuration saved in ./results\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1500\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-1000 (score: 0.4363941550254822).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1548, training_loss=0.4090772180286181, metrics={'train_runtime': 140.5884, 'train_samples_per_second': 44.043, 'train_steps_per_second': 11.011, 'total_flos': 410119066238976.0, 'train_loss': 0.4090772180286181, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff37913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
